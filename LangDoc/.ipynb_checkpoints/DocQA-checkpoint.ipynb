{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f632301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: how to do QA with langchain? break it down into steps and relevant info for each step\n",
      "AI:  1. Identify the problem: The problem is to find Leo DiCaprio's girlfriend. \n",
      "2. Collect information: Gather facts about Leo DiCaprio and his girlfriend by searching online. \n",
      "3. Analyze the problem: Identify any relevant information that can help you answer the question.\n",
      "4. Brainstorm solutions: Consider possible ways to answer the question, such as using search engines, asking people who know Leo DiCaprio, or looking for news articles on the topic.\n",
      "5. Evaluate solutions: Analyze the pros and cons of each option and choose the best one.\n",
      "6. Execute the solution: Use the chosen solution to find Leo DiCaprio's girlfriend.\n",
      "7. Test the solution: Confirm that the answer provided is accurate. \n",
      "8. Assess the result: Evaluate the overall quality of the answer and identify areas for improvement.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    openai.api_key = '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'\n",
    "    if openai.api_key is None:\n",
    "        raise ValueError(\"Missing API Key!\")\n",
    "except Exception as e:\n",
    "    sys.stderr.write(str(e))\n",
    "    sys.exit(1)\n",
    "\n",
    "# Specify the file path of merged.txt\n",
    "merged_file_path = \"results/merged.txt\"\n",
    "\n",
    "# Read the content of merged.txt\n",
    "try:\n",
    "    with open(merged_file_path, \"r\", encoding='utf-8') as file:\n",
    "        document = file.read()\n",
    "except FileNotFoundError:\n",
    "    sys.stderr.write(f\"File {merged_file_path} not found.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Split document into sentences\n",
    "sentences = nltk.sent_tokenize(document)\n",
    "\n",
    "# Initialize TF-IDF vectorizer and fit to our sentences\n",
    "vectorizer = TfidfVectorizer().fit(sentences)\n",
    "sentence_vectors = vectorizer.transform(sentences)\n",
    "\n",
    "while True:\n",
    "    # Request user input for the question prompt or exit the loop\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Vectorize the question and calculate the cosine similarity with each sentence\n",
    "    question_vector = vectorizer.transform([user_input])\n",
    "    similarities = np.dot(sentence_vectors, question_vector.T).toarray().squeeze()\n",
    "\n",
    "    # Find the 5 most similar sentences\n",
    "    top_sentence_indices = np.argsort(similarities)[-5:]\n",
    "    top_sentences = [sentences[i] for i in reversed(top_sentence_indices)]\n",
    "\n",
    "    # Concatenate the top sentences and use them as the prompt\n",
    "    context = \" \".join(top_sentences)\n",
    "\n",
    "    # Prepare the chunk prompt\n",
    "    chunk_prompt = context + \"\\n\" + user_input\n",
    "\n",
    "    # Request completion for the chunk prompt\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=chunk_prompt,\n",
    "        max_tokens=4096 - len(chunk_prompt)\n",
    "    )\n",
    "\n",
    "    # Extract the completion text from the response\n",
    "    response_text = response.choices[0].text.strip()\n",
    "\n",
    "    # Print the response\n",
    "    print(\"DocQA: \", response_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e471f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
